0. 檔案介紹
/
cert_dataset.csv => 訓練用的資料集
malicious_dataset.csv =>　人工選出來的惡意憑證(136張)
target_dataset.csv => model分類成功的惡意憑證，將用於adversary attatck
BERT_model_cased.ipynb => 訓練cased BERT model的紀錄
BERT_model_uncased.ipynb => 訓練uncased BERT model的紀錄

program/
0_preprocessing.py => 生成csv資料集
1_train_model.py => 訓練 BERT model (cased or uncased)
2_check_malicious.py => 挑出部分壞憑證資料，並讓model將其分類，分類正確的資料將用於adversary
3_textattack1.py => 框架1 (有bug...)
4_textattack2.py => 框架2 (有bug...)
func_def.py => 定義的function

1. 
unhandled field
{'jurisdictionC': 10, 'jurisdictionST': 9, 'jurisdictionL': 1, 'businessCategory': 8, 'serialNumber': 8,
 'subjectAltName': 4, 'name': 2, 'initials': 2, 'dnQualifier': 2, 'street': 2}

影響的cert
benign: 10
malicious: 4

# 最後因為考量只選了四個欄位

2. 
因為有些O當中有使用',' 所以不能用','當作分隔符，不然會檢查錯誤。

3. 
benign missing percentage:
{'C': 0.9475, 'ST': 0.947875, 'L': 0.948125, 'O': 0.997125, 'OU': 0.9985, 'CN': 0.0515, 'emailAddress': 1.0}
 {'C': 7580, 'ST': 7583, 'L': 7585, 'O': 7977, 'OU': 7988, 'CN': 412, 'emailAddress': 8000}
{'C': 0.0, 'ST': 0.997625, 'L': 0.999125, 'O': 0.94625, 'OU': 0.996875, 'CN': 0.94725, 'emailAddress': 1.0}
 {'C': 0, 'ST': 7981, 'L': 7993, 'O': 7570, 'OU': 7975, 'CN': 7578, 'emailAddress': 8000}

malicous missing percentag:
{'C': 0.584, 'ST': 0.685, 'L': 0.6995, 'O': 0.5905, 'OU': 0.793, 'CN': 0.1105, 'emailAddress': 0.969}
 {'C': 1168, 'ST': 1370, 'L': 1399, 'O': 1181, 'OU': 1586, 'CN': 221, 'emailAddress': 1938}
{'C': 0.244, 'ST': 0.666, 'L': 0.689, 'O': 0.589, 'OU': 0.8075, 'CN': 0.455, 'emailAddress': 0.97}
 {'C': 488, 'ST': 1332, 'L': 1378, 'O': 1178, 'OU': 1615, 'CN': 910, 'emailAddress': 1940}

4.
train 1: 使用六個欄位去訓練 subject["C", "O", "CN"]、issuer["C", "O", "CN"]，但是準確率不高(低於0.8)
train 2: 選擇一張憑證中的四個欄位去訓練 subject["CN"]、issuer["C", "O", "CN"]
train 3: epoch 20, batch_size 64，結果依然不好
train 4: 採用 N/A方式處理，accuracy高於0.95，至於uncased和cased模型則沒差。
=> 可能資料的編碼方式嚴重影響準確率

5. textattack安裝
https://www.lfd.uci.edu/~gohlke/pythonlibs/#jpype
有一個很煩的套件要另外裝(pycld2)，要去下載檔案，而且要符合版本cp。
另外numpy 版本可能要調整，pip install numpy==1.20.3

6. 解析憑證問題
有時候會產生base64編碼或著是其他的非ascii碼(ex. unicode)，無法顯示到憑證中。
# 另外可以考慮加入不可見的文字或是中文到憑證中，去測試是否容易被分類成好的或壞的。

7. BERT model file (存放在雲端)
(1) BERT model uncased
https://drive.google.com/file/d/14vJGAnm2wnCZUa0exK8ZIUNSYmxaaQ2L/view?usp=drive_link
uncased ID => 14vJGAnm2wnCZUa0exK8ZIUNSYmxaaQ2L

(2) BERT model cased
https://drive.google.com/file/d/14ytriW0pmgBXhVzhQo-TkRPkuzct6Nvi/view?usp=drive_link
cased ID => 14ytriW0pmgBXhVzhQo-TkRPkuzct6Nvi

# BERT model太大且是用GPU訓練的，所以將其放到雲端，並選擇使用colab載入model(因為我電腦沒網卡)，
  用其做text attack。

8. colab 指令
在colab移動路徑 => %cd <dir>
在colab刪除檔案 => !rm -rf <dir>
!rm -rf Project

9. 目前任務
(1) 將資料夾內的malicous_dataset中的cert分類，取出預測正確的。(生成target_dataset.csv)
    malicious_dataset.csv => 136 data, 正確預測的有127筆資料，將用於adversary attack。
    # accuracy 0.93

(2) 學會使用textattack
    learning...
    GPT生成的code都有bug...
    
    # 參考資料
    https://blog.csdn.net/weixin_36378508/article/details/128035441?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169752309716800184113899%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=169752309716800184113899&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-3-128035441-null-null.142^v96^pc_search_result_base4&utm_term=textattack%20BERT&spm=1018.2226.3001.4187