Writing logs to ./outputs\2023-11-15-17-13-01-963739\train_log.txt.
Wrote original training args to ./outputs\2023-11-15-17-13-01-963739\training_args.json.
***** Running training *****
  Num examples = 4160
  Num epochs = 3
  Num clean epochs = 1
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient accumulation steps = 1
  Total optimization steps = 1586
==========================================================
Epoch 1
Running clean epoch 1/1
