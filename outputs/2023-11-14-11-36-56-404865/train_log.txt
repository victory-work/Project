Writing logs to ./outputs\2023-11-14-11-36-56-404865\train_log.txt.
Wrote original training args to ./outputs\2023-11-14-11-36-56-404865\training_args.json.
***** Running training *****
  Num examples = 4160
  Num epochs = 3
  Num clean epochs = 1
  Instantaneous batch size per device = 64
  Total train batch size (w. parallel, distributed & accumulation) = 256
  Gradient accumulation steps = 4
  Total optimization steps = 51
==========================================================
Epoch 1
Running clean epoch 1/1
