Writing logs to ./outputs\2023-11-14-11-38-42-817250\train_log.txt.
Wrote original training args to ./outputs\2023-11-14-11-38-42-817250\training_args.json.
***** Running training *****
  Num examples = 4160
  Num epochs = 3
  Num clean epochs = 1
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient accumulation steps = 4
  Total optimization steps = 199
==========================================================
Epoch 1
Running clean epoch 1/1
